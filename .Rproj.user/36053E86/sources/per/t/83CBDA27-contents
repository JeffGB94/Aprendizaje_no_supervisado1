---
title: "Aprendizaje no supervisado: Árboles de desición"
author:
- "Daniela Arbeláez Montoya"
- "Jefferson Gamboa Betancur"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F, error = F, 
                      out.width = '60%', fig.align = 'center', fig.pos= "h")
```

```{r out.width = '80%', fig.align = 'center', fig.pos= "h", echo = F}
require(knitr)
include_graphics("Trabajo1_Mod3_Sem0220_page-0001.jpg")
```

```{r out.width = '90%', fig.align = 'center', fig.pos= "h", echo = F}
include_graphics("Trabajo1_Mod3_Sem0220_page-0002.jpg")
```

```{r out.width = '90%', fig.align = 'center', fig.pos= "h", echo = F}
include_graphics("Trabajo1_Mod3_Sem0220_page-0003.jpg")
```

```{r out.width = '90%', fig.align = 'center', fig.pos= "h", echo = F}
include_graphics("Trabajo1_Mod3_Sem0220_page-0004.jpg")
```

# Solución

```{r}
require(ISLR)
datos <- Carseats
```

**Descripción de Carseats.**

Un conjunto de datos simulados que contiene las ventas de asientos de seguridad para niños en 400 tiendas diferentes.

**Formato**
Un marco de datos con 400 observaciones sobre las siguientes 11 variables.

**Descripción de las variables**

* *Sales*
Ventas unitarias (en miles) en cada ubicación

* *CompPrice*
Precio cobrado por la competencia en cada ubicación

* *Income*
Nivel de ingresos de la comunidad (en miles de dólares)

* *Advertising*
Presupuesto de publicidad local para la empresa en cada ubicación (en miles de dólares)

* *Population*
Tamaño de la población en la región (en miles)

* *Price*
Precio que cobra la empresa por los asientos de seguridad en cada sitio

* *ShelveLoc*
Un factor con niveles Malo, Bueno y Medio que indica la calidad de la ubicación de las estanterías para los asientos del automóvil en cada sitio.

* *Age*
Edad media de la población local

* *Education*
Nivel de educación en cada ubicación

* *Urban*
Un factor con niveles No y Sí para indicar si la tienda está en una ubicación urbana o rural.

* *US*
Un factor con niveles No y Sí para indicar si la tienda está en EE. UU. O no

## 1.a)

Los datos son particionados aleatoriamente en el 70% para entrenamiento (train) y el 30% de prueba (test)

```{r}
set.seed(123)
muestra <- sample(1:nrow(datos), size = floor(nrow(datos) * 0.7))
train <- datos[muestra, ]; test <- datos[-muestra, ]
```

## 1.b)

```{r }
require(tree)
require(MASS)

Reg.tree <- tree(Sales ~ ., data = datos, subset = muestra)
summary(Reg.tree)
plot(Reg.tree)
text(Reg.tree, pretty = 0)
```

Observe que el árbol de regresión consideró que las variables más importantes fueron:

*ShelveLoc:* Un factor con niveles Malo, Bueno y Medio que indica la calidad de la ubicación de las estanterías para los asientos del automóvil en cada sitio.

*Price:* Precio que cobra la empresa por los asientos de seguridad en cada sitio.

*CompPrice:* Precio cobrado por la competencia en cada ubicación.

*Age:* Edad media de la población local.

*Advertising:* Presupuesto de publicidad local para la empresa en cada ubicación (en miles de dólares)

La calidad de la ubicación en las estanterías para los asientos es la covariable más importante para determinar la venta unitaria en cada ubicación, donde el la venta promedio del asiento es más baja cuando la calidad del asiento esta entre baja y media, mientras que la venta promedio para la calidad del asiento cuando es alta crece.

```{r}
MSE1 <- mean((test$Sales - predict(Reg.tree, newdata = test))^2)
```

Y el MSE de prueba es de `r MSE1`

## 1.c)

Ahora se utilizará cv.tree para ver si una poda mejora su desempeño

```{r}
set.seed(123)
cv_Reg <- cv.tree(Reg.tree)
D.prueba <- data.frame(cv_Reg$size, cv_Reg$dev)
D.prueba <- D.prueba[which.min(D.prueba[,2]),]
plot(cv_Reg$size, cv_Reg$dev, type = "b", xlab = "Tree seze", ylab = "MSE de validación cruzada")
points(D.prueba[,1],D.prueba[,2], pch=19, cex=2, col="red")
legend("topright", inset = .05, legend=c("size = 8", "mín MSE = 1300.186"), cex=0.8, box.lty=0)

```

Luego se procede a realizar la poda con la funsión de R, prune.tree

```{r}
prune.Reg <- prune.tree(Reg.tree, best = 8)
plot(prune.Reg)
text(prune.Reg, pretty = 0)
```

```{r}
MSE2 <- mean((test$Sales - predict(prune.Reg, newdata = test))^2);
```
```{r echo = F}
require(kableExtra)

M <- data.frame(MSE1, MSE2)
names(M) <- c("MSE sin poda", "MSE con poda")

kable(
  M,
  align = "c",
  booktabs = TRUE
) %>% kable_styling(position = "center")

```
Como se logra detallar el MSE de prueba sin poda es mucho menor al MSE de prueba con poda, es decir que no podar el árbol con 8 nodos no ayuda a mejorar el modelo.

## 1.d)

```{r}
require(randomForest)
set.seed(123)

bas.Reg <- randomForest(Sales ~ . , data = datos, subset = muestra, mtry = 10, importance = TRUE)
importance(bas.Reg)
varImpPlot(bas.Reg)
MSE3 <- mean((test$Sales - predict(bas.Reg, newdata = test))^2)
```
Las covariables *ShelveLoc* y *Price* son las covariables con mayor importancia en la base de datos. El MSE de prueba que se obtuvo utilizando bagging fue de `r MSE3`

## 1.e)

Para bosques aleatorios se utilizará por defecto en mtry = p/3 para generar el bosque.

```{r}
set.seed(123)
rf.Reg <- randomForest(Sales ~ . , data = datos, subset = muestra, importance = TRUE)
MSE4 <- mean((test$Sales - predict(rf.Reg, newdata = test))^2)
```
El MSE de prueba para random forest es de `r MSE4`

```{r}
importance(rf.Reg)
varImpPlot(rf.Reg)
```
Para random forest se encuentra que las mismas dos covariables que se presentaron en bagging son las más importante.

Si se compara el MSE de prueba para el bagging y el de random forest es:

```{r}
M <- data.frame(MSE3, MSE4)
names(M) <- c("MSE bagging", "MSE random forest")

kable(
  M,
  align = "c",
  booktabs = TRUE
) %>% kable_styling(position = "center")
```

Se observa que a pesar de utilizar con bagging un m = 10 y para random forest un m = 10/3 se logra evidenciar el MSE de prueba del bagging es mucho más pequeño que el de random forest, esto es devido a que random forest tiene una presición mucho más baja que el otro método utilizado.

## 2.a)

## 2.b)

## 2.c)

## 2.d)

## 3.a)

## 3.b)

## 3.c)

## 3.d)

## 3.e)

## 3.f)

## 3.g)

## 3.h)

## 4.a)

## 4.b)

## 4.c)

## 4.d)

## 4.e)

## 4.f)

## 4.g)

## 5.a)

## 5.b)

## 5.c)

## 5.d)
